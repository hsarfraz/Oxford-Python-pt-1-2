{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Assignment\n",
    "\n",
    "For this assignment you will have to identify a suitable dataset and implement a machine learning pipeline, comprising the following steps:\n",
    "\n",
    "* Presentation of the problem (6 points)\n",
    "* data exploration (4 points)\n",
    "* data preparation (10 points)\n",
    "* model selection: try 2 models (max 3) (20 points)\n",
    "* evaluation on test set (3 points)\n",
    "* conclusion commenting on the results and comparing the models (7 points)\n",
    "\n",
    "**Total: 50 points**\n",
    "\n",
    "Some possible datasets:\n",
    "* [Titanic dataset](https://www.kaggle.com/c/titanic): binary classification\n",
    "* [Wine dataset](https://www.kaggle.com/datasets/yasserh/wine-quality-dataset): multi-class classification/regression\n",
    "* [Abalone dataset](https://www.kaggle.com/datasets/rodolfomendes/abalone-dataset): regression\n",
    "* [California housing price](https://www.kaggle.com/datasets/camnugent/california-housing-prices): regression\n",
    "* [CIFAR-10](http://www.cs.toronto.edu/~kriz/cifar.html): multi-class classification in images\n",
    "\n",
    "Look for more on [Kaggle](https://www.kaggle.com/datasets) or elsewhere.\n",
    "\n",
    "**Deadline:** To be confirmed by the tutor - please see the date on our Canvas page.\n",
    "\n",
    "**Submission:** Please email your solutions and your completed Declaration of Authorship (DoA) form to weeklyclasses@conted.ox.ac.uk "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation of the problem (6 points)\r\n",
    "I am going to build on the NYC flights data that I breifly explored in \"Python for Data Science Part 1\"\n",
    "\n",
    "## Introduction to the dataset\n",
    "\n",
    "The New York City (nyc) flight data can be imported from the `flights` library in the `nycflights13` python data package. It contains data of flights that departed from three NYC airports (JFK, LGA or EWR) in 2013. The dataset contains a lot of information about each flight such as what time it departed, when it arrived, was the flight delayed, etc.\n",
    "\n",
    "## Introduction to the problem that I want to solve\n",
    "\n",
    "I thought that it would be useful to create a machine learning model that could identify/predict which flights will get cancelled given the departure delay, airline carrier, and travel distance. Many people don't know if their flight will be cancelled and this uncertinity might cause anxiety when travelling. Creating a flight cancelation predictor migtht help prepare individuals about whether they will expereince any flight cancelations when traveling. \n",
    "\n",
    "I believe it would be interesting to see if a model can give a approximate prediction of when a flight might be delayed given these factors. The reason I am using these three variables (departure delay, airline carrier, and travel distance) to predict flight cancelation is because I believe that these variables might play a crucial role in flight delays (ex. if a flight has a huge departure delay then it would most probably be cancelled, some airline carriers might be known to cancel their flights more often, perhaps flights with longer travel distances are more prone to cancellations) -I will explore these observations/correlations in the data exploration section  \n",
    "\n",
    "# Data Exploration (4 points)\n",
    "\n",
    "*   To begin exploring the data I printed the first five rows of the dataset to get a better understanding of the information that I am given. This is where I picked the input variables that the machine learning model is going to use to predict whether a flight is cancelled or not. \n",
    "*   I then checked the unique values in the `year` column to make sure that the flights dataset only contains 2013 flights data. This helped me understand the data that I am dealing with and will help me in my explainations.\n",
    "*   Lastly, I created a summary statisitic table to get a better idea of each variable. I noticed that departure delay and arival delay had positive and negative values and I assumed that these variables would only contain positive values. I realised that the positve numbers meant that the flight departed early. I believe that having positive and negative numbers to represent the departure delay will help the machine learning model in predicting whether a flight will be cancelled.ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installed the `nycflights13` python data package for nyc flight data\n",
    "#pip install nycflights13\n",
    "#pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>sched_dep_time</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>sched_arr_time</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>carrier</th>\n",
       "      <th>flight</th>\n",
       "      <th>tailnum</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>time_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>517.0</td>\n",
       "      <td>515</td>\n",
       "      <td>2.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>819</td>\n",
       "      <td>11.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>1545</td>\n",
       "      <td>N14228</td>\n",
       "      <td>EWR</td>\n",
       "      <td>IAH</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1400</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2013-01-01T10:00:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>533.0</td>\n",
       "      <td>529</td>\n",
       "      <td>4.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>830</td>\n",
       "      <td>20.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>1714</td>\n",
       "      <td>N24211</td>\n",
       "      <td>LGA</td>\n",
       "      <td>IAH</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1416</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>2013-01-01T10:00:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>542.0</td>\n",
       "      <td>540</td>\n",
       "      <td>2.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>850</td>\n",
       "      <td>33.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>1141</td>\n",
       "      <td>N619AA</td>\n",
       "      <td>JFK</td>\n",
       "      <td>MIA</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1089</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>2013-01-01T10:00:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>544.0</td>\n",
       "      <td>545</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>1022</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>B6</td>\n",
       "      <td>725</td>\n",
       "      <td>N804JB</td>\n",
       "      <td>JFK</td>\n",
       "      <td>BQN</td>\n",
       "      <td>183.0</td>\n",
       "      <td>1576</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>2013-01-01T10:00:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>554.0</td>\n",
       "      <td>600</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>812.0</td>\n",
       "      <td>837</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>461</td>\n",
       "      <td>N668DN</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>116.0</td>\n",
       "      <td>762</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01T11:00:00Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n",
       "0  2013      1    1     517.0             515        2.0     830.0   \n",
       "1  2013      1    1     533.0             529        4.0     850.0   \n",
       "2  2013      1    1     542.0             540        2.0     923.0   \n",
       "3  2013      1    1     544.0             545       -1.0    1004.0   \n",
       "4  2013      1    1     554.0             600       -6.0     812.0   \n",
       "\n",
       "   sched_arr_time  arr_delay carrier  flight tailnum origin dest  air_time  \\\n",
       "0             819       11.0      UA    1545  N14228    EWR  IAH     227.0   \n",
       "1             830       20.0      UA    1714  N24211    LGA  IAH     227.0   \n",
       "2             850       33.0      AA    1141  N619AA    JFK  MIA     160.0   \n",
       "3            1022      -18.0      B6     725  N804JB    JFK  BQN     183.0   \n",
       "4             837      -25.0      DL     461  N668DN    LGA  ATL     116.0   \n",
       "\n",
       "   distance  hour  minute             time_hour  \n",
       "0      1400     5      15  2013-01-01T10:00:00Z  \n",
       "1      1416     5      29  2013-01-01T10:00:00Z  \n",
       "2      1089     5      40  2013-01-01T10:00:00Z  \n",
       "3      1576     5      45  2013-01-01T10:00:00Z  \n",
       "4       762     6       0  2013-01-01T11:00:00Z  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nycflights13 import flights #impoting the flights library which contains all the nyc flight data\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(flights)[0:5] #viewing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2013], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(flights)['year'].unique() #I am double-checking to see if all the flight data is from 2013 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>sched_dep_time</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>sched_arr_time</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>flight</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>336776.0</td>\n",
       "      <td>336776.000000</td>\n",
       "      <td>336776.000000</td>\n",
       "      <td>328521.000000</td>\n",
       "      <td>336776.000000</td>\n",
       "      <td>328521.000000</td>\n",
       "      <td>328063.000000</td>\n",
       "      <td>336776.000000</td>\n",
       "      <td>327346.000000</td>\n",
       "      <td>336776.000000</td>\n",
       "      <td>327346.000000</td>\n",
       "      <td>336776.000000</td>\n",
       "      <td>336776.000000</td>\n",
       "      <td>336776.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>6.548510</td>\n",
       "      <td>15.710787</td>\n",
       "      <td>1349.109947</td>\n",
       "      <td>1344.254840</td>\n",
       "      <td>12.639070</td>\n",
       "      <td>1502.054999</td>\n",
       "      <td>1536.380220</td>\n",
       "      <td>6.895377</td>\n",
       "      <td>1971.923620</td>\n",
       "      <td>150.686460</td>\n",
       "      <td>1039.912604</td>\n",
       "      <td>13.180247</td>\n",
       "      <td>26.230100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.414457</td>\n",
       "      <td>8.768607</td>\n",
       "      <td>488.281791</td>\n",
       "      <td>467.335756</td>\n",
       "      <td>40.210061</td>\n",
       "      <td>533.264132</td>\n",
       "      <td>497.457142</td>\n",
       "      <td>44.633292</td>\n",
       "      <td>1632.471938</td>\n",
       "      <td>93.688305</td>\n",
       "      <td>733.233033</td>\n",
       "      <td>4.661316</td>\n",
       "      <td>19.300846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>-43.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-86.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>907.000000</td>\n",
       "      <td>906.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>1104.000000</td>\n",
       "      <td>1124.000000</td>\n",
       "      <td>-17.000000</td>\n",
       "      <td>553.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>502.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1401.000000</td>\n",
       "      <td>1359.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>1535.000000</td>\n",
       "      <td>1556.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>1496.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>872.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1744.000000</td>\n",
       "      <td>1729.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1940.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3465.000000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>1389.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>2359.000000</td>\n",
       "      <td>1301.000000</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>2359.000000</td>\n",
       "      <td>1272.000000</td>\n",
       "      <td>8500.000000</td>\n",
       "      <td>695.000000</td>\n",
       "      <td>4983.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           year          month            day       dep_time  sched_dep_time  \\\n",
       "count  336776.0  336776.000000  336776.000000  328521.000000   336776.000000   \n",
       "mean     2013.0       6.548510      15.710787    1349.109947     1344.254840   \n",
       "std         0.0       3.414457       8.768607     488.281791      467.335756   \n",
       "min      2013.0       1.000000       1.000000       1.000000      106.000000   \n",
       "25%      2013.0       4.000000       8.000000     907.000000      906.000000   \n",
       "50%      2013.0       7.000000      16.000000    1401.000000     1359.000000   \n",
       "75%      2013.0      10.000000      23.000000    1744.000000     1729.000000   \n",
       "max      2013.0      12.000000      31.000000    2400.000000     2359.000000   \n",
       "\n",
       "           dep_delay       arr_time  sched_arr_time      arr_delay  \\\n",
       "count  328521.000000  328063.000000   336776.000000  327346.000000   \n",
       "mean       12.639070    1502.054999     1536.380220       6.895377   \n",
       "std        40.210061     533.264132      497.457142      44.633292   \n",
       "min       -43.000000       1.000000        1.000000     -86.000000   \n",
       "25%        -5.000000    1104.000000     1124.000000     -17.000000   \n",
       "50%        -2.000000    1535.000000     1556.000000      -5.000000   \n",
       "75%        11.000000    1940.000000     1945.000000      14.000000   \n",
       "max      1301.000000    2400.000000     2359.000000    1272.000000   \n",
       "\n",
       "              flight       air_time       distance           hour  \\\n",
       "count  336776.000000  327346.000000  336776.000000  336776.000000   \n",
       "mean     1971.923620     150.686460    1039.912604      13.180247   \n",
       "std      1632.471938      93.688305     733.233033       4.661316   \n",
       "min         1.000000      20.000000      17.000000       1.000000   \n",
       "25%       553.000000      82.000000     502.000000       9.000000   \n",
       "50%      1496.000000     129.000000     872.000000      13.000000   \n",
       "75%      3465.000000     192.000000    1389.000000      17.000000   \n",
       "max      8500.000000     695.000000    4983.000000      23.000000   \n",
       "\n",
       "              minute  \n",
       "count  336776.000000  \n",
       "mean       26.230100  \n",
       "std        19.300846  \n",
       "min         0.000000  \n",
       "25%         8.000000  \n",
       "50%        29.000000  \n",
       "75%        44.000000  \n",
       "max        59.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(flights).describe() #summary statistics of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   To prepare the data I first need to create a new column which specifies whether a flight got cancelled or not. To do this I first check and see if there are any `NA` values in the arrival and departure delay columns because this would be an indication that a flight was cancelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of NA values in the departure delay columns are:  8255\n",
      "The number of NA values in the arrival delay columns are:  9430\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(flights)\n",
    "print('The number of NA values in the departure delay columns are: ', df['dep_delay'].isna().sum())\n",
    "print('The number of NA values in the arrival delay columns are: ', df['arr_delay'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   I noticed that there are more NA values under the arrival delay column. I thought that the count of the NA values for the departure and arrival delays would be the same, but after specificaly printing out the NA values in both columns I can see that there are some situations where a flight did have a set departure delay but it never had a arrival delay (keep in mind that the arrival delay column has values ranging from the negatives to the positives so the value under this column can represent flights that arrived early or on time). This probably means that the flights got cancelled due to an unexpected reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>sched_dep_time</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>sched_arr_time</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>carrier</th>\n",
       "      <th>flight</th>\n",
       "      <th>tailnum</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>time_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EV</td>\n",
       "      <td>4308</td>\n",
       "      <td>N18120</td>\n",
       "      <td>EWR</td>\n",
       "      <td>RDU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>416</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>2013-01-01T21:00:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>791</td>\n",
       "      <td>N3EHAA</td>\n",
       "      <td>LGA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1389</td>\n",
       "      <td>19</td>\n",
       "      <td>35</td>\n",
       "      <td>2013-01-02T00:00:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>1925</td>\n",
       "      <td>N3EVAA</td>\n",
       "      <td>LGA</td>\n",
       "      <td>MIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1096</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01T20:00:00Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n",
       "838  2013      1    1       NaN            1630        NaN       NaN   \n",
       "839  2013      1    1       NaN            1935        NaN       NaN   \n",
       "840  2013      1    1       NaN            1500        NaN       NaN   \n",
       "\n",
       "     sched_arr_time  arr_delay carrier  flight tailnum origin dest  air_time  \\\n",
       "838            1815        NaN      EV    4308  N18120    EWR  RDU       NaN   \n",
       "839            2240        NaN      AA     791  N3EHAA    LGA  DFW       NaN   \n",
       "840            1825        NaN      AA    1925  N3EVAA    LGA  MIA       NaN   \n",
       "\n",
       "     distance  hour  minute             time_hour  \n",
       "838       416    16      30  2013-01-01T21:00:00Z  \n",
       "839      1389    19      35  2013-01-02T00:00:00Z  \n",
       "840      1096    15       0  2013-01-01T20:00:00Z  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['dep_delay'].isna()].head(3) #there are situations where both the arrival and departure delay columns have no value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>sched_dep_time</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>sched_arr_time</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>carrier</th>\n",
       "      <th>flight</th>\n",
       "      <th>tailnum</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>time_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>1530</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>1805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MQ</td>\n",
       "      <td>4525</td>\n",
       "      <td>N719MQ</td>\n",
       "      <td>LGA</td>\n",
       "      <td>XNA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1147</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>2013-01-01T20:00:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1528.0</td>\n",
       "      <td>1459</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>1647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EV</td>\n",
       "      <td>3806</td>\n",
       "      <td>N17108</td>\n",
       "      <td>EWR</td>\n",
       "      <td>STL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>872</td>\n",
       "      <td>14</td>\n",
       "      <td>59</td>\n",
       "      <td>2013-01-01T19:00:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>1745</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2158.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MQ</td>\n",
       "      <td>4413</td>\n",
       "      <td>N739MQ</td>\n",
       "      <td>LGA</td>\n",
       "      <td>XNA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1147</td>\n",
       "      <td>17</td>\n",
       "      <td>45</td>\n",
       "      <td>2013-01-01T22:00:00Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n",
       "471  2013      1    1    1525.0            1530       -5.0    1934.0   \n",
       "477  2013      1    1    1528.0            1459       29.0    2002.0   \n",
       "615  2013      1    1    1740.0            1745       -5.0    2158.0   \n",
       "\n",
       "     sched_arr_time  arr_delay carrier  flight tailnum origin dest  air_time  \\\n",
       "471            1805        NaN      MQ    4525  N719MQ    LGA  XNA       NaN   \n",
       "477            1647        NaN      EV    3806  N17108    EWR  STL       NaN   \n",
       "615            2020        NaN      MQ    4413  N739MQ    LGA  XNA       NaN   \n",
       "\n",
       "     distance  hour  minute             time_hour  \n",
       "471      1147    15      30  2013-01-01T20:00:00Z  \n",
       "477       872    14      59  2013-01-01T19:00:00Z  \n",
       "615      1147    17      45  2013-01-01T22:00:00Z  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['arr_delay'].isna()].head(3) #there are situations where a departure delay is listed, but the arrival delay is NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>sched_dep_time</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>sched_arr_time</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>carrier</th>\n",
       "      <th>flight</th>\n",
       "      <th>tailnum</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>time_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>627.0</td>\n",
       "      <td>630</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US</td>\n",
       "      <td>27</td>\n",
       "      <td>N535UW</td>\n",
       "      <td>JFK</td>\n",
       "      <td>PHX</td>\n",
       "      <td>330.0</td>\n",
       "      <td>2153</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>2013-01-01T11:00:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>807.0</td>\n",
       "      <td>810</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>1043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>269</td>\n",
       "      <td>N308DE</td>\n",
       "      <td>JFK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>126.0</td>\n",
       "      <td>760</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2013-01-01T13:00:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1241.0</td>\n",
       "      <td>1241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>1847</td>\n",
       "      <td>N956DL</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>129.0</td>\n",
       "      <td>762</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01T15:00:00Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n",
       "35   2013      1    1     627.0             630       -3.0    1018.0   \n",
       "114  2013      1    1     807.0             810       -3.0    1043.0   \n",
       "217  2013      1    1     956.0            1000       -4.0    1241.0   \n",
       "\n",
       "     sched_arr_time  arr_delay carrier  flight tailnum origin dest  air_time  \\\n",
       "35             1018        0.0      US      27  N535UW    JFK  PHX     330.0   \n",
       "114            1043        0.0      DL     269  N308DE    JFK  ATL     126.0   \n",
       "217            1241        0.0      DL    1847  N956DL    LGA  ATL     129.0   \n",
       "\n",
       "     distance  hour  minute             time_hour  \n",
       "35       2153     6      30  2013-01-01T11:00:00Z  \n",
       "114       760     8      10  2013-01-01T13:00:00Z  \n",
       "217       762    10       0  2013-01-01T15:00:00Z  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['arr_delay'] == 0].head(3) #the arrival delay column contains on-time flight arrivals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   I am dropping the columns that I do not need. After looking at the dataset again I have decided to also keep the `hour` column since I believe that the hour of the day might also play a role of when flights will most probably not be cancelled\n",
    "*   I then created the cancelled column which marks a flight as cancelled if the result is one and a flight as not cancelled if the value is a zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, ['dep_delay', 'arr_delay', 'carrier', 'distance', 'hour']]\n",
    "df['cancelled'] = ( flights['arr_delay'].isna() ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     dep_delay  arr_delay carrier  distance  hour  cancelled\n",
      "471       -5.0        NaN      MQ      1147    15          1\n",
      "477       29.0        NaN      EV       872    14          1\n",
      "\n",
      "   dep_delay  arr_delay carrier  distance  hour  cancelled\n",
      "0        2.0       11.0      UA      1400     5          0\n",
      "1        4.0       20.0      UA      1416     5          0\n"
     ]
    }
   ],
   "source": [
    "print(df[df['cancelled'] == 1].head(2)) #one represents cancelled flights that did not have a arrival time\n",
    "print()\n",
    "print(df[df['cancelled'] == 0].head(2)) #zero represents non-cancelled flights that arrived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Now that I have created the column of cancelled flights I will be creating the training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#training and testing dataset split\n",
    "features = df[['dep_delay', 'carrier', 'distance', 'hour']]\n",
    "target = df['cancelled']\n",
    "\n",
    "# Imputeing missing values in 'departure_delay' column\n",
    "imputer = SimpleImputer(strategy='constant', fill_value=-999)\n",
    "features['departure_delay_imputed'] = imputer.fit_transform(features.loc[:,['dep_delay']])\n",
    "features.drop(columns=['dep_delay'], inplace=True) #removing the dep_delay column\n",
    "\n",
    "\n",
    "#label encoding for the `carrier` column\n",
    "label_encoder = LabelEncoder()\n",
    "features['airline_encoded'] = label_encoder.fit_transform(features['carrier']) # Converting the strings in the 'carrier' column to numerical values (label encoding)\n",
    "features.drop(columns=['carrier'], inplace=True) #removing the carrier column\n",
    "\n",
    "#training and testing data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42, stratify = target)\n",
    "\n",
    "#feature scaling (standardisation)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(269420, 4) (67356, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model selection: try 2 models (max 3) (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   I will be using three supervised learning tasks/models for the flight cancellation prediction (Random Forest, Logistic Regression, and Support Vector Machines -SVM)\n",
    "*   I will first run the models on the training dataset and will produce the results of the classification. I will then compare the results on the test data which will be on the next section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.9977841288694232\n",
      "Confusion Matrix:\n",
      "[[261872      4]\n",
      " [   593   6951]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    261876\n",
      "           1       1.00      0.92      0.96      7544\n",
      "\n",
      "    accuracy                           1.00    269420\n",
      "   macro avg       1.00      0.96      0.98    269420\n",
      "weighted avg       1.00      1.00      1.00    269420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Train the model\n",
    "RF_model = RandomForestClassifier(random_state=42)\n",
    "RF_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = RF_model.predict(X_train_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy on training data:\", accuracy_score(y_train, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9965370054190483\n",
      "\n",
      "Confusion Matrix:\n",
      " [[261876      0]\n",
      " [   933   6611]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    261876\n",
      "           1       1.00      0.88      0.93      7544\n",
      "\n",
      "    accuracy                           1.00    269420\n",
      "   macro avg       1.00      0.94      0.97    269420\n",
      "weighted avg       1.00      1.00      1.00    269420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR_model = LogisticRegression(random_state=42)\n",
    "LR_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = LR_model.predict(X_train_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_train, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9965370054190483\n",
      "\n",
      "Confusion Matrix:\n",
      " [[261876      0]\n",
      " [   933   6611]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    261876\n",
      "           1       1.00      0.88      0.93      7544\n",
      "\n",
      "    accuracy                           1.00    269420\n",
      "   macro avg       1.00      0.94      0.97    269420\n",
      "weighted avg       1.00      1.00      1.00    269420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train an SVM model\n",
    "SVC_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "SVC_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = SVC_model.predict(X_train_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_train, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation on test set (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.995828137062771\n",
      "\n",
      "Confusion Matrix on test data:\n",
      " [[65428    42]\n",
      " [  239  1647]]\n",
      "\n",
      "Classification Report on test data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     65470\n",
      "           1       0.98      0.87      0.92      1886\n",
      "\n",
      "    accuracy                           1.00     67356\n",
      "   macro avg       0.99      0.94      0.96     67356\n",
      "weighted avg       1.00      1.00      1.00     67356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred_test = RF_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "print(\"Accuracy on test data:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"\\nConfusion Matrix on test data:\\n\", confusion_matrix(y_test, y_pred_test))\n",
    "print(\"\\nClassification Report on test data:\\n\", classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classification on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9964071500682938\n",
      "\n",
      "Confusion Matrix:\n",
      " [[65470     0]\n",
      " [  242  1644]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     65470\n",
      "           1       1.00      0.87      0.93      1886\n",
      "\n",
      "    accuracy                           1.00     67356\n",
      "   macro avg       1.00      0.94      0.96     67356\n",
      "weighted avg       1.00      1.00      1.00     67356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_test = LR_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_test))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Classification on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9964071500682938\n",
      "\n",
      "Confusion Matrix:\n",
      " [[65470     0]\n",
      " [  242  1644]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     65470\n",
      "           1       1.00      0.87      0.93      1886\n",
      "\n",
      "    accuracy                           1.00     67356\n",
      "   macro avg       1.00      0.94      0.96     67356\n",
      "weighted avg       1.00      1.00      1.00     67356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_test = SVC_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_test))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion commenting on the results and comparing the models (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at all the F1 scores and confusion matrices of all the models I have come to the conclusion that the logistic and SVM classification algorithms are the most accurate as compared to random forest classification (I came to this conclusion after looking at the models performance on the test datasets. Initially, I thought that the random forest classifier was the most accurate model but my initial observations turned out to be incorrect)\n",
    "\n",
    "Random Forest Classification\n",
    "\n",
    "*  On the training dataset, the random forest classifier was able to correctly classify 261,872 non-cancelled flights and 6,951 cancelled flights. The F1 score for non-cancelled flights was 1 and for cancelled flights it was 0.96\n",
    "*  On the test dataset, the random forest classifier was able to correctly classify 65,428 non-cancelled flights and 1,647 cancelled flights. The F1 score for non-cancelled flights was 1 and for cancelled flights it was 0.92\n",
    "\n",
    "Logistic Regression Classification\n",
    "\n",
    "*  On the training dataset, the logistic regression classifier was able to correctly classify 261,876 non-cancelled flights and 6,611 cancelled flights. The F1 score for non-cancelled flights was 1 and for cancelled flights it was 0.93\n",
    "*  On the test dataset, the logistic regression classifier was able to correctly classify 65,470 non-cancelled flights and 1,644 cancelled flights. The F1 score for non-cancelled flights was 1 and for cancelled flights it was 0.93\n",
    "\n",
    "Support Vector Machines (SVM) Classification\n",
    "\n",
    "*  On the training dataset, the SVM classifier was able to correctly classify 261,876 non-cancelled flights and 6,611 cancelled flights. The F1 score for non-cancelled flights was 1 and for cancelled flights it was 0.93\n",
    "*  On the test dataset, the SVM classifier was able to correctly classify 65,470 non-cancelled flights and 1,644 cancelled flights. The F1 score for non-cancelled flights was 1 and for cancelled flights it was 0.93\n",
    "\n",
    "As you can see, the F1 scores for the random forest were the highest when compared to the logistic regression and SVM classifiers. But this value decreased when the classifer was used on the test data. I did see that on the test data, the Random Forest Classifer did correct classify more cancelled flights when compared to the logistic and SVM classifer but this difference is three which is not much. However, if you look at the amount of non-cancelled flights the Random Forest classifier fell short and could not correctly identify 42 more non-cancelled flights while the logistic and SVM classifer did correctly classify these values.\n",
    "\n",
    "Comparing the F1 scores of all three classifiers on both the training and test data I can say that all three models perform really closley and are fairly accurate. But when you only look at the training data results you would assume that the Random Forest classifier is the best classification task to use since it has F1 scores of 1 and 0.96 for the non-cancelled and cancelled flights respectivley. But when you look at the test data results you notice that the random forest F1 score for cancelled flights drops to 0.92 which suggests that perhaps the Random Forest classifier might not be the best classifier to use since the logistic and SVM classifiers have the highest F1 score of 0.93 for cancelled flights (this difference is not huge but if someone wants to go for a little bit more accuracy then I would go with the logisitc and SVM classifiers to perform this supervised learning classification task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "867df1ee534d26f2c7c906fca85dfba438b7170d4a41fa95ef57b9d1241c9022"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
